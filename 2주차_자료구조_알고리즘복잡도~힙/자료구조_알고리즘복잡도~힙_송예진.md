# 알고리즘 복잡도 표현 방법

### 1. 알고리즘 복잡도 계산이 필요한 이유

하나의 문제를 푸는 알고리즘은 다양할 수 있음

- 정수의 절대값 구하기
    - 방법1: 정수값을 제곱한 값에 다시 루트를 씌우기
    - 방법2: 정수가 음수인지 확인해서, 음수일 때만, -1을 곱하기
    
    ⇒ 다양한 알고리즘 중 어느 알고리즘이 더 좋은지를 분석하기 위해, 복잡도를 정의하고 계산함
    

### 2. 알고리즘 복잡도 계산 항목

1. 시간 복잡도: 알고리즘 실행 속도
2. 공간 복잡도: 알고리즘이 사용하는 메모리 사이즈

⇒ 가장 중요한 시간 복잡도를 꼭 이해하고 계산할 수 있어야 함. 

### 알고리즘 시간 복잡도의 주요 요소

- 반복문
    - 입력의 크기가 커질수록 반복문이 알고리즘 수행 시간을 지배함.

### 알고리즘 성능 표기법

- Big-O(빅-오) 표기법: O(N)
    - 알고리즘 최악의 실행시간을 표기
    - 가장 많이/일반적으로 사용함
    - 아무리 최악의 상황이라도, 이정도의 성능은 보장한다는 의미이기 때문
- 오메가 표기법
    - 오메가 표기법은 알고리즘 최상의 실행 시간을 표기
- 세타 표기법
    - 오메가 표기법은 알고리즘 평균 실행 시간을 표기

⇒ 시간 복잡도 계산은 반복문이 핵심 요소임을 인지하고, 계산 표기는 최상, 평균, 최악 중, 최악의 시간인 Big-O 표기법을 중심으로 익히면 됨.

### 대문자 O 표기법

- 빅 오 표기법, Big-O 표기법 이라고도 부름
- O(입력)
    - 입력 n 에 따라 결정되는 시간 복잡도 함수
- $O(1), O(logn), O(n), O(nlogn), O(n^2), O(2^n), O(n!)$ 등으로 표기함
- 입력 n 의 크기에 따라 기하급수적으로 시간 복잡도가 늘어날 수 있음
    - $O(1)< O(logn)< O(n)< O(nlogn)< O(n^2)< O(2^n)< O(n!)$
        - 참고: $log n$ 의 베이스는 $2-log_2n$
- 단순하게 입력 n에 따라, 몇 번 실행이 되는지를 계산하면 됩니다.
    - 표현식에 가장 큰 영향을 미치는 n 의 단위로 표기합니다.
    - n이 1이든 100이든, 1000이든, 10000이든 실행을
        - 무조건 2회(상수회) 실행한다: O(1)
            
            ```python
            if n > 10:
            	print(n)
            ```
            
        - n에 따라, n번, n + 10 번, 또는 3n + 10 번 등 실행한다: O(n)
            
            ```python
            variable = 10
            for index in range(n):
            	print(index)
            
            ---
            > n + 10번 실행
            ---
            variable = 10
            for num in range(3):
            	for index in range(n):
            		print(index)
            ---
            > 3n + 10번 실행
            
            ==> n의 값이 무한정으로 클 수도 있기 때문에 상수, 앞에 곱해지는 3 등은 Big-O 에 따지지 않음. 
            ```
            
        - n에 따라, $n^2$번, $n^2$ + 1000 번, 또는 100$n^2$ - 100 번등 실행한다: O($n^2$)
            
            ```python
            variable = 10
            
            for i in range(300):
            	for num in range(n):
            		for index in range(n):
            			print(index)
            ```

# 해쉬

+) 해쉬 기능 확장해서 블록체인에도 많이 씀.

### 1. 해쉬 구조

- Hash Table: 키(Key)에 데이터(Value)를 저장하는 데이터 구조
    - Key를 통해 바로 데이터를 받아올 수 있으므로, 속도가 획기적으로 빨라짐 (→ 배열은 첫번째 인덱스부터 순서대로 조회해야해서 속도가 빠르지 않음)
    - 파이썬 딕셔너리(Dictionary) 타입이 해쉬 테이블의 예시임→ Key를 가지고 바로 데이터(Value)를 꺼냄
    - 보통 배열로 미리 Hash Table 사이즈만큼 생성 후에 사용 (공간과 탐색 시간을 맞바꾸는 기법)
        - 공간을 늘림으로 충돌로 인한 추가적인 자료구조 알고리즘을 실행하지 않게 함.
    - 단, 파이썬에서는 해쉬를 별도 구현할 이유가 없음 - 딕셔너리 타입을 사용하면 됨

### 2. 알아둘 용어

- 해쉬(Hash): 임의 값을 고정 길이로 변환하는 것
    - 블록체인: 블록이라는 방대한 데이터라 할지라도 고정된 길이의 값으로 블록 값을 변환시켜서 가져올 수 있게 함.
- 해쉬 테이블(Hash Table): 키 값의 연산에 의해 직접 접근이 가능한 데이터 구조
    - 해쉬 값과 슬롯을 가짐.
- 해싱 함수(Hashing Function): Key에 대해 산술 연산을 이용해 데이터 위치를 찾을 수 있는 함수
    - input: key
    - output: 해쉬 주소
- 해쉬 값(Hash Value) 또는 해쉬 주소(Hash Address): Key를 해싱 함수로 연산해서, 해쉬 값을 알아내고, 이를 기반으로 해쉬 테이블에서 해당 Key에 대한 데이터 위치를 일관성 있게 찾을 수 있음
- 슬롯(Slot): 한 개의 데이터를 저장할 수 있는 공간
- 저장할 데이터에 대해 Key를 추출할 수 있는 별도 함수도 존재할 수 있음 (참고)

```python
#리스트 변수 활용한 해쉬 테이블 구현
#1. 해쉬 함수: key % 8
#2. 해쉬 키 생성: hash(data)

hash_table = list([0 for i in range(8)])

def get_key(data):
	return hash(data)

def hash _function(key):
	return key % 8

def save_data(data, value):
	hash_address = hash_function(get_key(data))
	hash_table[hash_address] = value

def read_data(data):
	hash_address = hash _function(get_key(data))
	return hash_table[hash_address]

-------- 출력 ----------
save_data('Dave', '0102030200') 
save_data('Andy', '01033232200')
read_data('Dave')

> '0102030200'

hash_table

> ['0102030200', 0, 0, 0, 0, 0, 0, 01033232200']
```

### 3. 자료 구조 해쉬 테이블의 장단점과 주요 용도

- 장점
    - 데이터 저장/읽기 속도가 빠르다. (검색 속도가 빠르다,)
    - 해쉬는 키에 대한 데이터가 있는지(중복) 확인이 쉬움
        - 배열은 중복 여부를 따지려면 배열 전체를 순회해야하지만, 해쉬는 데이터 → key → 해쉬 함수 → 해쉬 테이블 거쳐서 바로 확인 가능함.
- 단점
    - 일반적으로 저장공간이 좀더 많이 필요하다.
        - 데이터가 3개더라도 미리 저장공간을 크게 잡아둠. → 작게 잡으면 중복 발생할 가능성이 높아진다.
    - 여러 키에 해당하는 주소가 동일할 경우 충돌을 해결하기 위한 별도 자료구조가 필요함
        - 해쉬 테이블 공간이 작으면 충돌날 가능성이 높아짐. (테이블 공간 많이 잡아두면 중복 가능성 적어지긴 함)
- 주요 용도
    - 검색이 많이 필요한 경우
    - 저장, 삭제, 읽기가 빈번한 경우
    - 캐쉬 구현시 (중복 확인이 쉽기 때문)
        - 캐쉬: 바뀐 데이터만 새로 가져와서 화면에 빠르게 보일 수 있게 함 → 캐시에 있는 데이터의 유무를 따질 수 빠르게 따질 수 있음.

### 4. 충돌(Collision) 해결 알고리즘 (좋은 해쉬 함수 사용하기)
- 해쉬 테이블의 가장 큰 문제는 충돌(Collision)의 경우입니다. 이 문제를 충돌(Collision) 또는 해쉬 충돌(Hash Collision)이라고 부릅니다.

- Chaining 기법
    - 개방 해슁 또는 Open Hashing 기법 중 하나: 해쉬 테이블 저장공간 외의 공간을 활용하는 기법
        - 충돌이 발생한 데이터는 해쉬 테이블 외의 공간에 따로 저장함.
    - 충돌이 일어나면, 링크드 리스트라는 자료 구조를 사용해서, 링크드 리스트로 데이터를 추가로 뒤에 연결시켜서 저장하는 기법
- Linear Probing 기법
    - 폐쇄 해슁 또는 Close Hashing 기법 중 하나: 해쉬 테이블 저장공간 안에서 충돌 문제를 해결하는 기법
        - 보통 해쉬 테이블 저장공간은 데이터 크기에 비해서는 크다는 점을 이용해서,충돌 발생하면 내부에 비어있는 다른 공간을 사용함.
    - 충돌이 일어나면, 해당 hash address의 다음 address부터 맨 처음 나오는 빈공간에 저장하는 기법
        - 저장공간 활용도를 높이기 위한 기법
          
---

# 트리


### 1. 트리 (Tree) 구조

- 트리: Node와 Branch를 이용해서, 사이클을 이루지 않도록 구성한 데이터 구조
- 실제로 어디에 많이 사용되나?
    - 트리 중 이진 트리 (Binary Tree) 형태의 구조로, 탐색(검색) 알고리즘 구현을 위해 많 이 사용됨 (branch가 최대 2개)

### 2. 알아둘 용어

- Node: 트리에서 데이터를 저장하는 기본 요소 (데이터와 다른 연결된 노드에 대한 Branch 정보 포함)
- Root Node: 트리 맨 위에 있는 노드
- Level: 최상위 노드를 Level 0으로 하였을 때, 하위 Branch로 연결된 노드의 깊이를 나타냄
    - 최상위 노드를 Level 1로 둘 때도 있음.
- Parent Node: 어떤 노드의 다음 레벨에 연결된 노드 (부모 노드)
- Child Node: 어떤 노드의 상위 레벨에 연결된 노드 (자식 노드)
- Leaf Node (Terminal Node): Child Node가 하나도 없는 노드
- Sibling (Brother Node): 동일한 Parent Node를 가진 노드
- Depth: 트리에서 Node가 가질 수 있는 최대 Level

### 3. 이진 트리와 이진 탐색 트리 (Binary Search Tree)

- 이진 트리: 노드의 최대 Branch가 2인 트리
- 이진 탐색 트리 (Binary Search Tree, BST): 이진 트리에 다음과 같은 추가적인 조건이 있는 트리
    - 왼쪽 노드는 해당 노드(부모 노드)보다 작은 값, 오른쪽 노드는 해당 노드보다 큰 값을 가지고 있음!

### 4. 자료 구조 이진 탐색 트리의 장점과 주요 용도

- 주요 용도: 데이터 검색(탐색)
- 장점: 탐색 속도를 개선할 수 있음

### 5. 이진 탐색 트리 삭제

- leaf node 삭제
    - 그냥 삭제하고 끝
- child node가 하나인 node 삭제
    - node 대신 child node로
- child node가 두 개인 node 삭제
    - 삭제할 node의 오른쪽 자식 중, 가장 작은 값을 삭제할 node의 자리에 가도록 한다.
    - 삭제할 node의 왼쪽 자식 중, 가장 큰 값을 삭제할 node의 자리에 가도록 한다.

### 6. 이진 탐색 트리의 시간 복잡도와 단점

6.1. 시간 복잡도 (탐색시)

- depth (트리의 높이) 를 h라고 표기한다면, O(h)
- n개의 노드를 가진다면,  $h= log_2n$ 에 가까우므로, 시간 복잡도는  $O(logn)$
    - 참고: 빅오 표기법에서  $logn$ 에서의 $log$의 밑은 10이 아니라, 2입니다.
        - 한번 실행시마다, 50%의 실행할 수도 있는 명령을 제거한다는 의미. 즉 50%의 실행시간을 단축시킬 수 있다는 것을 의미함
- 평균 시간 복잡도는 O(logn) 이지만, 이는 트리가 균형잡혀 있을 때의 평균 시간복잡도이며, 다음 예와 같이 구성되어 있을 경우, 최악의 경우는 링크드 리스트등과 동일한 성능을 보여줌 (O(r))

---

# 힙

### 1. 힙이란?

- 힙: 데이터에서 최대값과 최소값을 빠르게 찾기 위해 고안된 완전 이진 트리(Complete Binary Tree)
    - 완전 이진 트리: 노드를 삽입할 때 최하단 왼쪽 노드부터 차례대로 삽입하는 트리
- 힙을 사용하는 이유
    - 배열에 데이터를 넣고, 최대값과 최소값을 찾으려면 $O(n)$ 이 걸림
    - 이에 반해, 힘에 데이터를 넣고, 최대값과 최소값을 찾으면, $O(logn$) 이 걸림
    - 우선순위 큐와 같이 최대값 또는 최소값을 빠르게 찾아야 하는 자료구조 및 알고리즘 구현 등에 활용됨

### 2. 힙 (Heap) 구조

- 힙은 최대값을 구하기 위한 구조 (최대 힙, Max Heap) 와, 최소값을 구하기 위한 구조 (최소 힙, Min Heap)로 분류할 수 있음
- 힙은 다음과 같이 두 가지 조건을 가지고 있는 자료구조임
    - 각 노드의 값은 해당 노드의 자식 노드가 가진 값보다 크거나 같다. (최대 의 경우)
        - 최소 힙의 경우는 각 노드의 값은 해당 노드의 자식 노드가 가진 값보다 크거나 작음
    - 완전 이진 트리 형태를 가짐 (왼쪽 최하단부 노드부터 채워지는 형태로 삽입된다.)

### 힙과 이진 탐색 트리의 공통점과 차이점

- 공통점
    - 힙과 이진 탐색 트리는 모두 이진 트리임
- 차이점
    - 힙은 각 노드의 값이 자식 노드보다 크거나 같음(Max Heap의 경우)
    - 이진 탐색 트리는 왼쪽 자식 노드의 값이 가장 작고, 그 다음 부모 노드, 그 다음 오른쪽 자식 노드 값이 가장 큼
    - 힙은 이진 탐색 트리의 조건인 자식 노드에서 작은 값은 왼쪽, 큰 값은 오른쪽이라는 조건은 없음
        - 힙의 왼쪽 및 오른쪽 자식 노드의 값은 오른쪽이 클 수도 있고, 왼쪽이 클 수도 있음 (부모 노드보다 작기만 하면 된다.)
    - 이진 탐색 트리는 탐색을 위한 구조, 힙은 최대/최소값 검색을 위한 구조 중 하나로 이해하면 됨

### 힙의 데이터 삽입,삭제

- 만약 추가하는 데이터가 부모 노드보다 크다? → 일단 최하단의 비어있는 노드로 채운 다음에 최대힙 기준 충족할 때까지 swap

- 보통 삭제는 최상단 노드(root)를 삭제하는 것이 일반적임
    - 힙의 용도는 최대값 또는 최소값을 root노드에 놓아서, 최대값과 최소값을 바로 꺼내 쓸 수 있도록 하는 것임
    - 상단의 데이터 삭제시, 가장 최하단부 왼쪽에 위치한 노드(일반적으로 가장 마지막에 추가한 노드)를 root 노드로 이동
    - root 노드의 값이 자식 노드보다 작을 경우, swap을 반복함.
  
